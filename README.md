# ğŸ“ Machine_Learning_Courses
J'apprends ici de A Ã  Z le machine learning avec Python

## ğŸ§  Introduction au Machine Learning

### Qu'est-ce que le Machine Learning ?
- DÃ©finition
- DiffÃ©rences avec lâ€™intelligence artificielle
- Types de machine learning : supervisÃ©, non supervisÃ©, par renforcement

### Domaines d'application
- Finance, santÃ©, marketing, reconnaissance faciale, etc.

### CatÃ©gories d'apprentissage
- SupervisÃ©
- Non supervisÃ©
- Par renforcement
- Semi-supervisÃ©

### Ã‰tapes de construction d'un modÃ¨le ML
1. DÃ©finition du problÃ¨me
2. Collecte des donnÃ©es
3. Nettoyage et traitement des donnÃ©es
4. SÃ©lection des variables pertinentes
5. EntraÃ®nement des modÃ¨les
6. Choix du meilleur modÃ¨le
7. Validation et Ã©valuation
8. ImplÃ©mentation et tests

---

## ğŸ§® MaÃ®trise des Outils Python

### Numpy
- Tableaux multidimensionnels
- OpÃ©rations vectorielles

### Pandas
- SÃ©ries et DataFrames
- Manipulation de donnÃ©es

### Matplotlib & Seaborn
- Visualisation simple vs avancÃ©e
- Graphiques statistiques : histogramme, boxplot, heatmap

---

## ğŸ“Š Statistiques et ProbabilitÃ©s

### Concepts de base
- Moyenne, mÃ©diane, mode
- Variance, Ã©cart-type

### Types de variables
- Quantitatives (discrÃ¨tes, continues)
- Qualitatives (ordinales, nominales)

### Lois de probabilitÃ©
- Binomiale, normale, loi de Poisson

### Statistiques bivariÃ©es
- CorrÃ©lation
- RÃ©gression simple

---

## ğŸ“ MÃ©thodes Factorielles

### ACP, AFC, ACM
- DÃ©finition et applications
- InterprÃ©tation des axes
- Visualisation des donnÃ©es

### VÃ©rification de la normalitÃ©
- Tests de Shapiro-Wilk, Anderson-Darling

---

## âš™ï¸ PrÃ©traitement des DonnÃ©es

### Normalisation vs Standardisation
- MÃ©thodes et cas dâ€™usage

### Encodage des variables catÃ©gorielles
- Label Encoding
- One-Hot Encoding

### Transformation des variables
- Box-Cox, Yeo-Johnson
- Logarithmique, Puissance

### DonnÃ©es manquantes
- Identification
- Imputation

### Outliers
- DÃ©tection (IQR, Z-score)
- Traitement

---

## ğŸ“Œ SÃ©lection de Variables

### Approches de filtrage
- CorrÃ©lations
- Tests statistiques

### Approches automatiques/intÃ©grÃ©es
- RFE
- Lasso, Random Forest importance

---

## ğŸ—ï¸ ModÃ©lisation supervisÃ©e

### RÃ©gression linÃ©aire
- HypothÃ¨ses
- MÃ©triques (MSE, RÂ²)
- Cas de non-validation

### RÃ©gression logistique
- HypothÃ¨ses
- Avantages / inconvÃ©nients
- Utilisation pour la classification

### Ã‰valuation de la performance
- MÃ©triques : prÃ©cision, rappel, F1
- Fonctions de perte

### Overfitting vs Underfitting
- Solutions : rÃ©gularisation, validation croisÃ©e

---

## ğŸ” Apprentissage non supervisÃ©

### Clustering
- K-means
- CAH
- DBSCAN

---

## ğŸ“ˆ SÃ©ries temporelles

### Concepts clÃ©s
- StationnaritÃ©
- ModÃ¨les ARIMA, VAR, VEC

### Applications
- PrÃ©diction de cours boursiers
- Analyse des tendances

---

## ğŸ§¬ Algorithmes de machine learning

### KNN, SVM, Arbres de dÃ©cision
- Principes et cas dâ€™usage
- ParamÃ©trage

### ForÃªts alÃ©atoires et Ensemble Learning
- Bagging, Boosting, Stacking
- XGBoost, LightGBM, CatBoost

---

## ğŸ—£ï¸ Machine Learning avec donnÃ©es non structurÃ©es

### NLP & Analyse de sentiments
- RÃ©gression logistique
- TextBlob et NLTK

### Images, audio, vidÃ©o
- Traitements spÃ©cifiques
- Convolution & Deep Learning (Ã  approfondir)

---

## ğŸ” InterprÃ©tabilitÃ© des modÃ¨les

### Outils
- LIME
- SHAP
- DPD

---
